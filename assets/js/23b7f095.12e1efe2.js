"use strict";(self.webpackChunkaurorahelp=self.webpackChunkaurorahelp||[]).push([[3143],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>p});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var c=n.createContext({}),s=function(e){var t=n.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},u=function(e){var t=s(e.components);return n.createElement(c.Provider,{value:t},e.children)},g="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,c=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),g=s(a),m=i,p=g["".concat(c,".").concat(m)]||g[m]||d[m]||r;return a?n.createElement(p,o(o({ref:t},u),{},{components:a})):n.createElement(p,o({ref:t},u))}));function p(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,o=new Array(r);o[0]=m;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[g]="string"==typeof e?e:i,o[1]=l;for(var s=2;s<r;s++)o[s]=a[s];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},9647:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>g,frontMatter:()=>r,metadata:()=>l,toc:()=>s});var n=a(7462),i=(a(7294),a(3905));const r={authors:"Hunter",tags:["AI Hallucination","Clinical Documentation","Training Data Limitations","Medical Language Complexity","RAG (Retrieval-augmented Generation)","AuroraPrime Create","Fact-Checking","Large Language Model (LLM)","AuroraPrime Create"]},o="Combating AI Hallucination in Medical Writing",l={permalink:"/blog/2024/10/08/ Combating AI Hallucination in Medical Writing",source:"@site/blog/2024-10-08 Combating AI Hallucination in Medical Writing.md",title:"Combating AI Hallucination in Medical Writing",description:"How AuroraPrime Create Ensures Accurate Clinical Documentation",date:"2024-10-08T00:00:00.000Z",formattedDate:"October 8, 2024",tags:[{label:"AI Hallucination",permalink:"/blog/tags/ai-hallucination"},{label:"Clinical Documentation",permalink:"/blog/tags/clinical-documentation"},{label:"Training Data Limitations",permalink:"/blog/tags/training-data-limitations"},{label:"Medical Language Complexity",permalink:"/blog/tags/medical-language-complexity"},{label:"RAG (Retrieval-augmented Generation)",permalink:"/blog/tags/rag-retrieval-augmented-generation"},{label:"AuroraPrime Create",permalink:"/blog/tags/aurora-prime-create"},{label:"Fact-Checking",permalink:"/blog/tags/fact-checking"},{label:"Large Language Model (LLM)",permalink:"/blog/tags/large-language-model-llm"}],readingTime:3.125,hasTruncateMarker:!1,authors:[{name:"Hunter Shen",title:"generative AI evangelist",imageURL:"https://video.myaurora.cn/adhoc/huntershen.jpeg",key:"Hunter"}],frontMatter:{authors:"Hunter",tags:["AI Hallucination","Clinical Documentation","Training Data Limitations","Medical Language Complexity","RAG (Retrieval-augmented Generation)","AuroraPrime Create","Fact-Checking","Large Language Model (LLM)","AuroraPrime Create"]},nextItem:{title:"How to Master the Art of Prompt Writing for AI Models in Medical Writing",permalink:"/blog/2024/09/28/ How to Master the Art of Prompt Writing for AI Models in Medical Writing"}},c={authorsImageUrls:[void 0]},s=[{value:"Why AI Hallucination Happens",id:"why-ai-hallucination-happens",level:2},{value:"Address AI Hallucination in Medical Writing Using AuroraPrime Create",id:"address-ai-hallucination-in-medical-writing-using-auroraprime-create",level:2},{value:"RAG-powered Knowledge Base",id:"rag-powered-knowledge-base",level:3},{value:"Use a Large Language Model with Higher Long-form Factuality Performance",id:"use-a-large-language-model-with-higher-long-form-factuality-performance",level:3},{value:"Prompt Tuning",id:"prompt-tuning",level:3},{value:"Fact-Checking",id:"fact-checking",level:3},{value:"Wrapping Up",id:"wrapping-up",level:2}],u={toc:s};function g(e){let{components:t,...r}=e;return(0,i.kt)("wrapper",(0,n.Z)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"How AuroraPrime Create Ensures Accurate Clinical Documentation")),(0,i.kt)("p",null,(0,i.kt)("img",{src:a(160).Z,width:"1792",height:"1024"})),(0,i.kt)("p",null,"The medical writing industry is increasingly leaning towards integrating AI to streamline documentation processes. However, these opportunities come with significant challenges. "),(0,i.kt)("p",null,"One of the Challenges Facing Medical Writers is AI Hallucination. AI hallucination is a phenomenon where the model output is fabricated and not grounded by either the provided context or world knowledge. This can be particularly problematic in clinical documentation. Imagine an AI referencing studies, clinical trials, or research papers that don't exist. The consequences of such hallucinations can be grave, leading to misinformation and potentially harmful decisions in medical practice. "),(0,i.kt)("h2",{id:"why-ai-hallucination-happens"},"Why AI Hallucination Happens"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Training Data Limitations"),': AI models are trained on extensive datasets available up to a specific cut-off date. When the model encounters topics with limited or inconsistent training data, it may "hallucinate" by generating content that sounds plausible but is inaccurate.'),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Complexity of Medical Language"),": Medical writing often involves highly technical language, complex relationships between terms, and specific regulatory standards, which increases the risk of hallucination if the AI doesn't fully understand these intricacies. Unlike generic knowledge, the knowledge required for creating clinical documents is exclusive to related organizations or even study-specific."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Model Configuration"),": The default temperature of the Large Language Model (LLM) being used may dictate its creativity, which may not be configured by the end user. This can lead to more imaginative but less accurate outputs."),(0,i.kt)("h2",{id:"address-ai-hallucination-in-medical-writing-using-auroraprime-create"},"Address AI Hallucination in Medical Writing Using AuroraPrime Create"),(0,i.kt)("p",null,"Seamlessly integrated with Microsoft Word 365, AuroraPrime Create by AlphaLife Sciences is a Word add-in that harnesses generative AI to assist medical writers in creating clinical documentation. "),(0,i.kt)("h3",{id:"rag-powered-knowledge-base"},"RAG-powered Knowledge Base"),(0,i.kt)("p",null,"RAG (Retrieval-Augmented Generation) is a widely-used technique to enhance AI outputs by retrieving relevant documents and using them as additional context for generation. AuroraPrime Create enables you to easily build a corporate knowledge base that supports AI-driven content generation, seamlessly integrating it into your clinical documentation workflow. "),(0,i.kt)("p",null,"When generating an Initial Draft Document from a template in AuroraPrime Create, you can upload related documents for content reuse and repurposing. With AuroraPrime Create, you can effortlessly build a RAG-powered knowledge base, containing all relevant study information, to streamline your documentation process."),(0,i.kt)("h3",{id:"use-a-large-language-model-with-higher-long-form-factuality-performance"},"Use a Large Language Model with Higher Long-form Factuality Performance"),(0,i.kt)("p",null,"AuroraPrime Create gives you the flexibility to select the LLM that best suits your evolving content needs, ensuring you always use the model with the highest factual accuracy. "),(0,i.kt)("p",null,(0,i.kt)("img",{src:a(5808).Z,width:"1496",height:"676"}),"\n(Long-form factuality performance, measured for a list of mainstream models, using 250 random prompts from LongFact-Objects from\xa0",(0,i.kt)("a",{parentName:"p",href:"https://github.com/google-deepmind/long-form-factuality/tree/main/longfact"},"LongFact"),"\xa0benchmark. Image source:\xa0",(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2403.18802"},"Wei et al. 2024"),")"),(0,i.kt)("h3",{id:"prompt-tuning"},"Prompt Tuning"),(0,i.kt)("p",null,"Mainstream large language models possess an inherent capacity for self-awareness. AuroraPrime Create enhances this capability with built-in prompts specifically tuned to provide the appropriate context, further strengthening the model's self-knowledge. Users can also input additional prompts when generating AI-driven content, such as TFL summaries. This customization ensures that the AI model is aligned with the unique requirements and standards of the organization, further reducing the risk of hallucination. "),(0,i.kt)("h3",{id:"fact-checking"},"Fact-Checking"),(0,i.kt)("p",null,"Always verify AI-generated medical content against reliable data sources or knowledge bases, ensuring that referenced studies or clinical trials are real and accurately summarized."),(0,i.kt)("p",null,"The AuroraPrime Create add-in can automatically validate the accuracy and consistency of TFL summary objects against the TFL data, ensuring the summaries are coherent and aligned with their corresponding TFLs."),(0,i.kt)("h2",{id:"wrapping-up"},"Wrapping Up"),(0,i.kt)("p",null,"AI hallucination poses a significant challenge in medical writing, but tools like AuroraPrime Create offer robust solutions to mitigate these risks. By leveraging RAG-powered knowledge bases, choosing the right LLM, and incorporating rigorous fact-checking, medical writers can ensure the accuracy and reliability of their clinical documentation. As the industry continues to evolve, staying informed and utilizing advanced tools will be key to maintaining high standards in medical writing."))}g.isMDXComponent=!0},160:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/image_20241009141070-70c3c0a8427cbfa1221fbcba2e24db6e.png"},5808:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/image_20241009151090-d711e145ccc82b88048c1798030f5a2c.png"}}]);